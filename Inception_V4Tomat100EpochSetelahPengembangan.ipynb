{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception-V4Tomat50EpochAfterPengembangan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ-hTIsZckpr",
        "colab_type": "code",
        "outputId": "489136c1-1e23-458a-87a3-2922ea6f5ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import warnings\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D,Convolution2D,AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from keras import initializers\n",
        "from keras import backend as K\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0RvIiGXc7Oy",
        "colab_type": "code",
        "outputId": "9164bad1-8220-48ab-cf16-bd9f7b472fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdkTmIhddMEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_root = '/content/drive/My Drive/Dataset tomat/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCYu_eJsdQ0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, tuple((224,224)))   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfOPc7EEdmjD",
        "colab_type": "code",
        "outputId": "7501e221-5057-416b-fee5-b825e141fa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".jpeg\") == True or image_directory.endswith(\".png\") == True or image_directory.endswith(\".JPG\") == True :\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Tomato___Bacterial_spot ...\n",
            "[INFO] Processing Tomato___Early_blight ...\n",
            "[INFO] Processing Tomato___Leaf_Mold ...\n",
            "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Processing Tomato___Late_blight ...\n",
            "[INFO] Image loading completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxx5sjiCnlLb",
        "colab_type": "code",
        "outputId": "1ac59d1b-8114-4b53-e5d7-fc565251b0b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_size = len(image_list)\n",
        "image_size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff4zeHlCnoD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYqvbym2nqZC",
        "colab_type": "code",
        "outputId": "9afefacc-b47e-4380-bdeb-5db3b70f07ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
            " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
            " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dt3Q_y7nt2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abL0TFLTnvxl",
        "colab_type": "code",
        "outputId": "c51d8579-88b2-439f-bcc2-dac3c717034f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list,image_labels, test_size=0.2 , random_state =42) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la6OBsqYLnVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87033c28-3f65-4f60-fd3f-da9b9c2cfaa1"
      },
      "source": [
        "'''\n",
        "Copyright 2017 TensorFlow Authors and Kent Sommer\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "   http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "#########################################################################################\n",
        "# Implements the Inception Network v4 (http://arxiv.org/pdf/1602.07261v1.pdf) in Keras. #\n",
        "#########################################################################################\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x = np.divide(x, 255.0)\n",
        "    x = np.subtract(x, 0.5)\n",
        "    x = np.multiply(x, 2.0)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
        "              padding='same', strides=(1, 1), use_bias=False):\n",
        "    \"\"\"\n",
        "    Utility function to apply conv + BN. \n",
        "    (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
        "    \"\"\"\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "    x = Convolution2D(nb_filter, (num_row, num_col),\n",
        "                      strides=strides,\n",
        "                      padding=padding,\n",
        "                      use_bias=use_bias,\n",
        "                      kernel_regularizer=regularizers.l2(0.00004),\n",
        "                      kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_inception_a(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_reduction_a(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_inception_b(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_reduction_b(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_inception_c(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
        "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
        "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
        "\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
        "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
        "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
        "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def inception_v4_base(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
        "\n",
        "    #Stem Block\n",
        "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
        "    net = conv2d_bn(net, 64, 3, 3)\n",
        "\n",
        "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
        "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    # 35 x 35 x 384\n",
        "    # 4 x Inception-A blocks\n",
        "    for idx in range(4):\n",
        "    \tnet = block_inception_a(net)\n",
        "\n",
        "    # 35 x 35 x 384\n",
        "    # Reduction-A block\n",
        "    net = block_reduction_a(net)\n",
        "\n",
        "    # 17 x 17 x 1024\n",
        "    # 7 x Inception-B blocks\n",
        "    for idx in range(7):\n",
        "    \tnet = block_inception_b(net)\n",
        "\n",
        "    # 17 x 17 x 1024\n",
        "    # Reduction-B block\n",
        "    net = block_reduction_b(net)\n",
        "\n",
        "    # 8 x 8 x 1536\n",
        "    # 3 x Inception-C blocks\n",
        "    for idx in range(3):\n",
        "    \tnet = block_inception_c(net)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
        "    '''\n",
        "    Creates the inception v4 network\n",
        "\n",
        "    Args:\n",
        "    \tnum_classes: number of classes\n",
        "    \tdropout_keep_prob: float, the fraction to keep before final layer.\n",
        "    \n",
        "    Returns: \n",
        "    \tlogits: the logits outputs of the model.\n",
        "    '''\n",
        "\n",
        "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        inputs = Input((3, 224, 224))\n",
        "    else:\n",
        "        inputs = Input((224, 224, 3))\n",
        "\n",
        "    # Make inception base\n",
        "    x = inception_v4_base(inputs)\n",
        "\n",
        "\n",
        "    # Final pooling and prediction\n",
        "    if include_top:\n",
        "      \n",
        "        # Final pooling and prediction\n",
        "        # 1 x 1 x 1536\n",
        "        x = AveragePooling2D((8,8), padding='valid')(x)\n",
        "        x = Dropout(dropout_keep_prob)(x)\n",
        "        x = Flatten()(x)\n",
        "        # 1536\n",
        "        x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, x, name='inception_v4')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'imagenet':\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            if K.backend() == 'tensorflow':\n",
        "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "        if include_top:\n",
        "            weights_path = get_file(\n",
        "                'inception-v4_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='9fe79d77f793fe874470d84ca6ba4a3b')\n",
        "        else:\n",
        "            weights_path = get_file(\n",
        "                'inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='9296b46b5971573064d12e4669110969')\n",
        "        model.load_weights(weights_path, by_name=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model(num_classes=1001, dropout_prob=0.2, weights=None, include_top=False):\n",
        "    return inception_v4(num_classes, dropout_prob, weights, include_top)\n",
        "# ----------------------------------------------------------\n",
        "incept_model = create_model(num_classes=1001, dropout_prob=0.2, weights=None, include_top=False)\n",
        "incept_model.load_weights('/content/drive/My Drive/input/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for l in incept_model.layers: \n",
        "    if l is not None: l.trainable = True \n",
        "        \n",
        "x = incept_model.output\n",
        "x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "x = BatchNormalization()(x)\n",
        "#x = Dense(1024, activation='relu')(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=incept_model.input, outputs=predictions)        \n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 96)   55296       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 96)   288         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 96)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 54, 54, 160)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 54, 54, 64)   10240       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 54, 54, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 54, 54, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 54, 54, 64)   28672       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 54, 54, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 54, 54, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 54, 54, 64)   10240       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 54, 54, 64)   28672       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 54, 54, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 54, 54, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 54, 54, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 54, 54, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 52, 52, 96)   55296       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 52, 52, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 52, 52, 96)   288         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 52, 52, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 52, 52, 96)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 52, 52, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 52, 52, 192)  0           activation_6[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 192)  331776      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 192)  576         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 192)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 25, 25, 384)  0           activation_11[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 384)  0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 96)   55296       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 96)   288         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 96)   288         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 96)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 96)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 25, 25, 384)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 384)  0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 96)   55296       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 96)   288         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 96)   288         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 96)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 96)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 25, 25, 384)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 64)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 64)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 25, 25, 96)   55296       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 25, 25, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 25, 25, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 384)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 25, 25, 96)   82944       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 96)   288         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 25, 25, 96)   288         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 25, 25, 96)   288         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 96)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 25, 25, 96)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 25, 25, 96)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 25, 25, 384)  0           activation_26[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 25, 25, 64)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 25, 25, 64)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 25, 25, 96)   55296       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 25, 25, 64)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 25, 25, 96)   288         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 25, 25, 64)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 25, 25, 96)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 25, 25, 384)  0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 25, 25, 96)   55296       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 25, 25, 96)   82944       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 25, 25, 96)   288         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 25, 25, 96)   288         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 25, 25, 96)   288         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 25, 25, 96)   288         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 25, 25, 96)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 25, 25, 96)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 25, 25, 96)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 25, 25, 96)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 25, 25, 384)  0           activation_33[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 25, 25, 192)  73728       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 25, 25, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 25, 25, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 25, 25, 224)  387072      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 25, 25, 224)  672         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 25, 25, 224)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 384)  1327104     concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 256)  516096      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 384)  1152        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 256)  768         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 384)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 256)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 384)  0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 12, 12, 1024) 0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  258048      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 224)  301056      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 192)  576         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 224)  672         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 192)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 224)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 224)  301056      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 224)  351232      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 224)  672         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 224)  672         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 224)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 224)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 1024) 0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 256)  401408      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 256)  401408      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 384)  1152        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 256)  768         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 256)  768         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 128)  384         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 384)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 256)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 256)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 128)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 12, 12, 1024) 0           activation_44[0][0]              \n",
            "                                                                 activation_47[0][0]              \n",
            "                                                                 activation_52[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  258048      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 224)  301056      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 192)  576         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 224)  672         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 192)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 224)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 224)  301056      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 224)  351232      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 224)  672         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 224)  672         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 224)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 224)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 1024) 0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 256)  401408      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 256)  401408      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 384)  1152        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 256)  768         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 256)  768         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 128)  384         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 384)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 256)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 256)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 128)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 12, 12, 1024) 0           activation_54[0][0]              \n",
            "                                                                 activation_57[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 224)  301056      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 224)  672         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 224)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 224)  301056      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 224)  351232      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 224)  672         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 224)  672         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 224)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 224)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 1024) 0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 256)  401408      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 256)  401408      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 384)  1152        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 256)  768         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 256)  768         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 128)  384         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 384)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 256)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 256)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 128)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 12, 12, 1024) 0           activation_64[0][0]              \n",
            "                                                                 activation_67[0][0]              \n",
            "                                                                 activation_72[0][0]              \n",
            "                                                                 activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 12, 12, 192)  576         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 192)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 12, 12, 192)  258048      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 12, 12, 192)  576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 192)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 12, 12, 224)  301056      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 12, 12, 224)  672         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 224)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 12, 12, 224)  301056      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 12, 12, 224)  351232      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 12, 12, 224)  672         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 12, 12, 224)  672         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 224)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 224)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 12, 12, 1024) 0           concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 12, 12, 256)  401408      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 12, 12, 256)  401408      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 384)  1152        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 12, 12, 256)  768         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 12, 12, 256)  768         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 12, 12, 128)  384         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 384)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 256)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 256)  0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 12, 12, 1024) 0           activation_74[0][0]              \n",
            "                                                                 activation_77[0][0]              \n",
            "                                                                 activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 12, 12, 192)  576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 192)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 12, 12, 192)  258048      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 12, 12, 192)  576         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 12, 12, 192)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 12, 12, 224)  301056      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 12, 12, 192)  576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 12, 12, 224)  672         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 192)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 12, 12, 224)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 12, 12, 224)  301056      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 12, 12, 224)  351232      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 12, 12, 224)  672         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 12, 12, 224)  672         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 224)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 12, 12, 224)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 12, 12, 1024) 0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 12, 12, 256)  401408      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 12, 12, 256)  401408      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 12, 12, 384)  1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 12, 12, 256)  768         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 12, 12, 256)  768         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 12, 12, 128)  384         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 384)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 256)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 12, 12, 256)  0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 12, 12, 128)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 12, 12, 1024) 0           activation_84[0][0]              \n",
            "                                                                 activation_87[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 12, 12, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 12, 12, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 12, 12, 192)  258048      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 12, 12, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 12, 12, 192)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 12, 12, 224)  301056      activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 12, 12, 192)  576         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 12, 12, 224)  672         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 12, 12, 192)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 12, 12, 224)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 12, 12, 224)  301056      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 12, 12, 224)  351232      activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 12, 12, 224)  672         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 12, 12, 224)  672         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 12, 12, 224)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 12, 12, 224)  0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 12, 12, 1024) 0           concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 12, 12, 256)  401408      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 12, 12, 256)  401408      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 12, 12, 384)  1152        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 12, 12, 256)  768         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 12, 12, 256)  768         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 12, 12, 128)  384         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 12, 12, 384)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 12, 12, 256)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 12, 12, 256)  0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 12, 12, 128)  0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 12, 12, 1024) 0           activation_94[0][0]              \n",
            "                                                                 activation_97[0][0]              \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 12, 12, 192)  576         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 12, 12, 192)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 12, 12, 192)  258048      activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 12, 12, 192)  576         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 12, 12, 192)  0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 12, 12, 224)  301056      activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 12, 12, 192)  576         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 12, 12, 224)  672         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 12, 12, 192)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 12, 12, 224)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 12, 12, 224)  301056      activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 12, 12, 224)  351232      activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 12, 12, 224)  672         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 12, 12, 224)  672         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 12, 12, 224)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 12, 12, 224)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 12, 12, 1024) 0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 12, 12, 256)  401408      activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 12, 12, 256)  401408      activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 12, 12, 384)  1152        conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 12, 12, 256)  768         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 12, 12, 256)  768         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 12, 12, 128)  384         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 12, 12, 384)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 12, 12, 256)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 12, 12, 256)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 12, 12, 128)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 12, 12, 1024) 0           activation_104[0][0]             \n",
            "                                                                 activation_107[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 12, 12, 256)  262144      concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 12, 12, 256)  768         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 12, 12, 256)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 12, 12, 256)  458752      activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 12, 12, 256)  768         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 12, 12, 256)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 12, 12, 320)  573440      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 12, 12, 192)  576         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 12, 12, 320)  960         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 12, 12, 192)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 12, 12, 320)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 5, 5, 192)    331776      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 5, 5, 320)    921600      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 5, 5, 192)    576         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 5, 5, 320)    960         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 5, 5, 192)    0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 5, 5, 320)    0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 1024)   0           concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 5, 5, 1536)   0           activation_115[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 5, 5, 384)    1152        conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 5, 5, 384)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 5, 5, 448)    516096      activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 5, 5, 448)    1344        conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 5, 5, 448)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 5, 5, 512)    688128      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 5, 5, 384)    1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 5, 5, 512)    1536        conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 5, 5, 384)    0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 5, 5, 512)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 5, 5, 256)    294912      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 5, 5, 256)    294912      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 5, 5, 256)    393216      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 5, 5, 256)    393216      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 5, 5, 1536)   0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 5, 5, 256)    768         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 5, 5, 256)    768         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 5, 5, 256)    768         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 5, 5, 256)    768         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 5, 5, 256)    768         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 5, 5, 256)    0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 5, 5, 256)    0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 5, 5, 256)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 5, 5, 256)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 5, 5, 256)    768         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 5, 5, 256)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 5, 5, 512)    0           activation_122[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 5, 5, 512)    0           activation_127[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 5, 5, 256)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 5, 5, 1536)   0           activation_120[0][0]             \n",
            "                                                                 concatenate_17[0][0]             \n",
            "                                                                 concatenate_18[0][0]             \n",
            "                                                                 activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 5, 5, 384)    1152        conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 5, 5, 384)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 5, 5, 448)    516096      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 5, 5, 448)    1344        conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 5, 5, 448)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 5, 5, 512)    688128      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 5, 5, 384)    1152        conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 5, 5, 512)    1536        conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 5, 5, 384)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 5, 5, 512)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 5, 5, 256)    294912      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 5, 5, 256)    294912      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 5, 5, 256)    393216      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 5, 5, 256)    393216      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 5, 5, 1536)   0           concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 5, 5, 256)    768         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 5, 5, 256)    768         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 5, 5, 256)    768         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 5, 5, 256)    768         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 5, 5, 256)    768         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 5, 5, 256)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 5, 5, 256)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 5, 5, 256)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 5, 5, 256)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 5, 5, 256)    768         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 5, 5, 256)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 5, 5, 512)    0           activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 5, 5, 512)    0           activation_137[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 5, 5, 256)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 5, 5, 1536)   0           activation_130[0][0]             \n",
            "                                                                 concatenate_20[0][0]             \n",
            "                                                                 concatenate_21[0][0]             \n",
            "                                                                 activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 5, 5, 384)    1152        conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 5, 5, 384)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 5, 5, 448)    516096      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 5, 5, 448)    1344        conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 5, 5, 448)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 5, 5, 512)    688128      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 5, 5, 384)    1152        conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 5, 5, 512)    1536        conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 5, 5, 384)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 5, 5, 512)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 5, 5, 256)    294912      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 5, 5, 256)    294912      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 5, 5, 256)    393216      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 5, 5, 256)    393216      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 5, 5, 1536)   0           concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 5, 5, 256)    768         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 5, 5, 256)    768         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 5, 5, 256)    768         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 5, 5, 256)    768         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 5, 5, 256)    768         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 5, 5, 256)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 5, 5, 256)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 5, 5, 256)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 5, 5, 256)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 5, 5, 256)    768         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 5, 5, 256)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 5, 5, 512)    0           activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 5, 5, 512)    0           activation_147[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 5, 5, 256)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 5, 5, 1536)   0           activation_140[0][0]             \n",
            "                                                                 concatenate_23[0][0]             \n",
            "                                                                 concatenate_24[0][0]             \n",
            "                                                                 activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 1536)         0           concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 1536)         6144        global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          786944      batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            3078        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 41,970,566\n",
            "Trainable params: 41,904,326\n",
            "Non-trainable params: 66,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkan5Ntpnx_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Define a function for a convolutional layer with batch normalization\n",
        "# #The commands in this function will be used very much, so it's simpler to define this function once. \n",
        "# def conv(input_, filters_, kernel_, strides_, bias_, padding_):\n",
        "#     conv_ = Conv2D(filters=filters_, kernel_size=kernel_, strides=strides_, use_bias=bias_, padding=padding_)(input_)\n",
        "#     #The batch normalization helps to prevent overfitting and better learning results by removing the covariance shift.\n",
        "#     conv_ = BatchNormalization(axis = -1, momentum = 0.9997, scale = False)(conv_)\n",
        "#     conv_ = Activation(\"relu\")(conv_)\n",
        "#     return conv_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cARQPIxrn1a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #All kinds of inception networks starting with a stem. The stem preprocesses \n",
        "# #the input.\n",
        "# def stem(input_):\n",
        "#     #First convolutional block\n",
        "#     stem_ = conv(input_, 32, (3,3), (2,2), False, \"valid\")\n",
        "#     stem_ = conv(stem_, 32, (1,3), (1,1), False, \"same\")\n",
        "#     stem_ = conv(stem_, 32, (3,1), (1,1), False, \"same\")\n",
        "#     stem_ = conv(stem_, 64, (1,3), (1,1), False, \"same\")\n",
        "#     stem_ = conv(stem_, 64, (3,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Instead of going deeper the network will becoming wider!\n",
        "#     stem_1 = conv(stem_, 96, (3,3), (2,2), False, \"valid\")\n",
        "#     stem_2 = MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"valid\")(stem_)\n",
        "#     #Concatenate stem_1 and stem_2\n",
        "#     stem_ = concatenate([stem_1, stem_2], axis = -1)\n",
        "    \n",
        "#     #In the next block we will also parallize two convolutional blocks\n",
        "#     #Here I reuse the two variable names from above\n",
        "#     stem_1 = conv(stem_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     stem_1 = conv(stem_1, 64, (7,1), (1,1), False, \"same\")\n",
        "#     stem_1 = conv(stem_1, 64, (1,7), (1,1), False, \"same\")\n",
        "#     stem_1 = conv(stem_1, 96, (1,3), (1,1), False, \"valid\")\n",
        "#     stem_1 = conv(stem_1, 96, (3,1), (1,1), False, \"valid\")\n",
        "#     stem_2 = conv(stem_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     stem_2 = conv(stem_2, 96, (3,3), (1,1), False, \"valid\")\n",
        "#     #Concatenate stem_1 and stem_2\n",
        "#     stem_ = concatenate([stem_1, stem_2], axis = -1)\n",
        "    \n",
        "#     #Third concatenation block\n",
        "#     #Reuse stem_1 and stem_2\n",
        "#     stem_1 = MaxPool2D(pool_size=(1,1), strides=(2,2), padding=\"valid\")(stem_)\n",
        "#     stem_2 = stem_1 = conv(stem_, 192, (3,3), (1,1), False, \"valid\")\n",
        "#     #Concatenate stem_1 and stem_2\n",
        "#     stem_ = concatenate([stem_1, stem_2], axis = -1)\n",
        "    \n",
        "#     return stem_  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO46g9_Pn4Dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def inception_A(input_):\n",
        "#     #In this block we parallize four convolutional blocks\n",
        "#     #First\n",
        "#     A_1 = conv(input_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     A_1 = conv(A_1, 96, (1,3), (1,1), False, \"same\")\n",
        "#     A_1 = conv(A_1, 96, (3,1), (1,1), False, \"same\")\n",
        "#     A_1 = conv(A_1, 96, (1,3), (1,1), False, \"same\")\n",
        "    \n",
        "    \n",
        "#     #Second\n",
        "#     A_2 = conv(input_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     A_2 = conv(A_2, 96, (1,3), (1,1), False, \"same\")\n",
        "#     A_2 = conv(A_2, 96, (3,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     A_3 = conv(input_, 96, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Fourth\n",
        "#     A_4 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input_)\n",
        "#     A_4 = conv(A_4, 96, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     A = concatenate([A_1, A_2, A_3, A_4], axis=-1)\n",
        "    \n",
        "#     return A    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U79A8hMHn6Ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def inception_B(input_):\n",
        "#     #Similiar to A\n",
        "#     #In this block we also parallize four convolutional blocks\n",
        "    \n",
        "#     #First\n",
        "#     B_1 = conv(input_, 192, (1,1), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 192, (1,7), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 224, (7,1), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 224, (1,7), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 256, (7,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Second\n",
        "#     B_2 = conv(input_, 192, (1,1), (1,1), False, \"same\")\n",
        "#     B_2 = conv(B_2, 224, (7,1), (1,1), False, \"same\")\n",
        "#     B_2 = conv(B_2, 256, (1,7), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     B_3 = conv(input_, 384, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Fourth\n",
        "#     B_4 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input_)\n",
        "#     B_4 = conv(B_4, 128, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     B = concatenate([B_1, B_2, B_3, B_4], axis=-1)\n",
        "    \n",
        "#     return B    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qReZNAwn8kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def inception_C(input_):\n",
        "#     #This block is different to the structures of the other two blocks\n",
        "    \n",
        "#     #First\n",
        "#     C_1 = conv(input_, 384, (1,1), (1,1), False, \"same\")\n",
        "#     C_1 = conv(C_1, 448, (1,3), (1,1), False, \"same\")\n",
        "#     C_1 = conv(C_1, 512, (3,1), (1,1), False, \"same\")\n",
        "#     #Split it up again\n",
        "#     C_11 = conv(C_1, 256, (1,3), (1,1), False, \"same\")\n",
        "#     C_12 = conv(C_1, 256, (3,1), (1,1), False, \"same\")\n",
        "#     #Concatenate it again\n",
        "#     C_1 = concatenate([C_11, C_12], axis=-1)\n",
        "    \n",
        "#     #Second\n",
        "#     C_2 = conv(input_, 384, (1,1), (1,1), False, \"same\")\n",
        "#     #Split it up again\n",
        "#     C_21 = conv(C_2, 256, (1,3), (1,1), False, \"same\")\n",
        "#     C_22 = conv(C_2, 256, (3,1), (1,1), False, \"same\")\n",
        "#     #Concatenate it again\n",
        "#     C_2 = concatenate([C_21, C_22], axis=-1)\n",
        "    \n",
        "#     #Third\n",
        "#     C_3 = conv(input_, 256, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Fourth\n",
        "#     C_4 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input_)\n",
        "#     C_4 = conv(C_4, 128, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     C = concatenate([C_1, C_2, C_3, C_4], axis=-1)\n",
        "    \n",
        "#     return C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzfUiKzmn--p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def reduction_1(input_):\n",
        "#     #Three parallized branches\n",
        "#     #We must choose four parameters (k,l,m,n) depending on the used network\n",
        "#     #The parameters are listed in a look up table in Paper 2\n",
        "#     k = 192\n",
        "#     l = 224\n",
        "#     m = 256\n",
        "#     n = 384\n",
        "    \n",
        "#     #First\n",
        "#     R_1 = conv(input_, k, (1,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, l, (1,3), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, l, (3,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, m, (3,3), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Second\n",
        "#     R_2 = conv(input_, n, (1,3), (2,2), False, \"same\")\n",
        "#     R_2 = conv(input_, n, (3,1), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     R_3 = MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"same\")(input_)\n",
        "    \n",
        "#     R = concatenate([R_1, R_2, R_3], axis=-1)\n",
        "    \n",
        "#     return R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoPfZkYloBam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def reduction_2(input_):\n",
        "#     #Second reduction module\n",
        "    \n",
        "#     #First\n",
        "#     R_1 = conv(input_, 256, (1,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, 256, (1,7), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, 320, (7,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, 320, (3,3), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Second\n",
        "#     R_2 = conv(input_, 192, (1,1), (1,1), False, \"same\")\n",
        "#     R_2 = conv(R_2, 192, (1,1), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     R_3 = MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"same\")(input_)\n",
        "    \n",
        "#     R = concatenate([R_1, R_2, R_3], axis=-1)\n",
        "    \n",
        "#     return R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpWL9L9uoDl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def pure_inception_v4(load_weights=True):\n",
        "    \n",
        "#     starter = Input((224, 224, 3))\n",
        "    \n",
        "#     #Start with the stem\n",
        "#     inc = stem(starter)\n",
        "    \n",
        "#     #inception block A\n",
        "#     inc = inception_A(inc)\n",
        "#     inc = Dropout(0.2)(inc)\n",
        "    \n",
        "#     #First Reduction\n",
        "#     inc = reduction_1(inc)\n",
        "    \n",
        "#     #innception block B\n",
        "#     inc = inception_B(inc)    \n",
        "#     inc = Dropout(0.2)(inc)\n",
        "    \n",
        "#     #Second Reduction\n",
        "#     inc = reduction_2(inc)\n",
        "    \n",
        "#     #inception block C\n",
        "#     inc = inception_C(inc)\n",
        "    \n",
        "#     #Average pooling\n",
        "#     inc = AveragePooling2D((3, 3))(inc)\n",
        "\n",
        "#     # Dropout\n",
        "#     inc = Dropout(0.2)(inc) # Keep dropout 0.2 as mentioned in the paper\n",
        "#     inc = Flatten()(inc)\n",
        "\n",
        "#     # Output layer\n",
        "#     output = Dense(units = 6 , activation = \"softmax\")(inc)\n",
        "    \n",
        "#     model = Model(starter, output, name = \"Inception-v4\")   \n",
        "        \n",
        "#     return model    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0moYIQTdoGZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model = pure_inception_v4()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtW0Qiy7oMoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(Model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSTZHNolvfIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:40]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[40:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQiovlHrvirP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We'll use the RMSprop optimizer with a learning rate of 0.0001\n",
        "#We'll use binary_crossentropy loss because its a binary classification\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=0.0001), metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS7yX9C_vkf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets create the augmentation configuration\n",
        "#This helps prevent overfitting, since we are using a small dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,   #Scale the image between 0 and 1\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UZ6Xy3-vpWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the image generators\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=4)\n",
        "val_generator = val_datagen.flow(x_test, y_test,batch_size=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6GXPXGSULBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HsVJ0x3vsji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82066b53-3106-43ae-ca0f-1be5da4142b5"
      },
      "source": [
        "%%time\n",
        "#The training part\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=len(x_train) // 4,\n",
        "                              epochs=50,\n",
        "                              validation_data=val_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/50\n",
            "240/240 [==============================] - 74s 309ms/step - loss: 1.0877 - acc: 0.8694 - val_loss: 1.3012 - val_acc: 0.8319\n",
            "Epoch 2/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 1.0463 - acc: 0.8851 - val_loss: 1.6046 - val_acc: 0.8035\n",
            "Epoch 3/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.9954 - acc: 0.9069 - val_loss: 2.3816 - val_acc: 0.7292\n",
            "Epoch 4/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 1.0024 - acc: 0.9087 - val_loss: 2.2675 - val_acc: 0.7292\n",
            "Epoch 5/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.9858 - acc: 0.9170 - val_loss: 1.5096 - val_acc: 0.7208\n",
            "Epoch 6/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.9814 - acc: 0.9182 - val_loss: 1.8841 - val_acc: 0.7167\n",
            "Epoch 7/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.9590 - acc: 0.9255 - val_loss: 3.1044 - val_acc: 0.7153\n",
            "Epoch 8/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.9474 - acc: 0.9333 - val_loss: 5.8682 - val_acc: 0.7333\n",
            "Epoch 9/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.9521 - acc: 0.9309 - val_loss: 5.8661 - val_acc: 0.7333\n",
            "Epoch 10/50\n",
            "240/240 [==============================] - 47s 198ms/step - loss: 0.9290 - acc: 0.9389 - val_loss: 5.8634 - val_acc: 0.7333\n",
            "Epoch 11/50\n",
            "240/240 [==============================] - 46s 193ms/step - loss: 0.9148 - acc: 0.9408 - val_loss: 4.5836 - val_acc: 0.7333\n",
            "Epoch 12/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.9345 - acc: 0.9387 - val_loss: 4.9483 - val_acc: 0.7208\n",
            "Epoch 13/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.9322 - acc: 0.9382 - val_loss: 3.3018 - val_acc: 0.7333\n",
            "Epoch 14/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.8955 - acc: 0.9462 - val_loss: 5.8518 - val_acc: 0.7153\n",
            "Epoch 15/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.8864 - acc: 0.9481 - val_loss: 4.5686 - val_acc: 0.7333\n",
            "Epoch 16/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.8924 - acc: 0.9446 - val_loss: 3.2848 - val_acc: 0.7333\n",
            "Epoch 17/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.8858 - acc: 0.9477 - val_loss: 5.8342 - val_acc: 0.7153\n",
            "Epoch 18/50\n",
            "240/240 [==============================] - 46s 192ms/step - loss: 0.8716 - acc: 0.9488 - val_loss: 5.8279 - val_acc: 0.7153\n",
            "Epoch 19/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.8393 - acc: 0.9519 - val_loss: 5.8197 - val_acc: 0.7194\n",
            "Epoch 20/50\n",
            "240/240 [==============================] - 47s 194ms/step - loss: 0.8466 - acc: 0.9524 - val_loss: 4.5365 - val_acc: 0.7333\n",
            "Epoch 21/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.8410 - acc: 0.9540 - val_loss: 3.2520 - val_acc: 0.7333\n",
            "Epoch 22/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.8220 - acc: 0.9578 - val_loss: 3.2449 - val_acc: 0.7208\n",
            "Epoch 23/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.8318 - acc: 0.9564 - val_loss: 3.2400 - val_acc: 0.7208\n",
            "Epoch 24/50\n",
            "240/240 [==============================] - 47s 198ms/step - loss: 0.8302 - acc: 0.9477 - val_loss: 3.2358 - val_acc: 0.7153\n",
            "Epoch 25/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.7953 - acc: 0.9609 - val_loss: 5.7870 - val_acc: 0.7153\n",
            "Epoch 26/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.7958 - acc: 0.9604 - val_loss: 5.7819 - val_acc: 0.7153\n",
            "Epoch 27/50\n",
            "240/240 [==============================] - 47s 194ms/step - loss: 0.7645 - acc: 0.9684 - val_loss: 5.7767 - val_acc: 0.7292\n",
            "Epoch 28/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.7649 - acc: 0.9648 - val_loss: 3.2144 - val_acc: 0.7292\n",
            "Epoch 29/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.7598 - acc: 0.9648 - val_loss: 3.2092 - val_acc: 0.7292\n",
            "Epoch 30/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.7426 - acc: 0.9700 - val_loss: 5.7597 - val_acc: 0.7153\n",
            "Epoch 31/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.7678 - acc: 0.9688 - val_loss: 3.1989 - val_acc: 0.7153\n",
            "Epoch 32/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.7468 - acc: 0.9644 - val_loss: 4.4721 - val_acc: 0.7153\n",
            "Epoch 33/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.7244 - acc: 0.9714 - val_loss: 5.7447 - val_acc: 0.7208\n",
            "Epoch 34/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.7370 - acc: 0.9656 - val_loss: 5.7403 - val_acc: 0.7333\n",
            "Epoch 35/50\n",
            "240/240 [==============================] - 47s 195ms/step - loss: 0.7169 - acc: 0.9688 - val_loss: 4.4569 - val_acc: 0.7208\n",
            "Epoch 36/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.7189 - acc: 0.9722 - val_loss: 4.4518 - val_acc: 0.7208\n",
            "Epoch 37/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.7262 - acc: 0.9658 - val_loss: 3.1699 - val_acc: 0.7292\n",
            "Epoch 38/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.7216 - acc: 0.9637 - val_loss: 5.7220 - val_acc: 0.7333\n",
            "Epoch 39/50\n",
            "240/240 [==============================] - 48s 198ms/step - loss: 0.6832 - acc: 0.9752 - val_loss: 4.4381 - val_acc: 0.7333\n",
            "Epoch 40/50\n",
            "240/240 [==============================] - 46s 193ms/step - loss: 0.6832 - acc: 0.9767 - val_loss: 5.7114 - val_acc: 0.7333\n",
            "Epoch 41/50\n",
            "240/240 [==============================] - 47s 194ms/step - loss: 0.7099 - acc: 0.9674 - val_loss: 4.4297 - val_acc: 0.7292\n",
            "Epoch 42/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.6947 - acc: 0.9684 - val_loss: 4.4259 - val_acc: 0.7333\n",
            "Epoch 43/50\n",
            "240/240 [==============================] - 47s 194ms/step - loss: 0.6961 - acc: 0.9701 - val_loss: 3.1444 - val_acc: 0.7333\n",
            "Epoch 44/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.6730 - acc: 0.9705 - val_loss: 5.6959 - val_acc: 0.7153\n",
            "Epoch 45/50\n",
            "240/240 [==============================] - 46s 193ms/step - loss: 0.6600 - acc: 0.9776 - val_loss: 3.1345 - val_acc: 0.7292\n",
            "Epoch 46/50\n",
            "240/240 [==============================] - 47s 196ms/step - loss: 0.6701 - acc: 0.9720 - val_loss: 4.4081 - val_acc: 0.7153\n",
            "Epoch 47/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.6577 - acc: 0.9743 - val_loss: 5.6804 - val_acc: 0.7292\n",
            "Epoch 48/50\n",
            "240/240 [==============================] - 47s 197ms/step - loss: 0.6710 - acc: 0.9705 - val_loss: 5.6758 - val_acc: 0.7333\n",
            "Epoch 49/50\n",
            "240/240 [==============================] - 46s 194ms/step - loss: 0.6237 - acc: 0.9793 - val_loss: 4.3924 - val_acc: 0.7194\n",
            "Epoch 50/50\n",
            " 92/240 [==========>...................] - ETA: 27s - loss: 0.6356 - acc: 0.9760"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxBEkRkmoU4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aug = ImageDataGenerator(\n",
        "#     rotation_range=25, width_shift_range=0.1,\n",
        "#     height_shift_range=0.1, shear_range=0.2, \n",
        "#     zoom_range=0.2,horizontal_flip=True, \n",
        "#     fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JID7NdgoXY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model.compile(loss=\"binary_crossentropy\", optimizer='Adam',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8qWcqbSoZfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = Model.fit_generator(\n",
        "#     aug.flow(x_train, y_train, batch_size=4),\n",
        "#     steps_per_epoch=len(x_train)//4,\n",
        "#     epochs=50,\n",
        "#     validation_data=(x_test, y_test),\n",
        "#     max_queue_size=4*2,\n",
        "#     verbose=1\n",
        "#     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AxTr7tU1NfS",
        "colab_type": "code",
        "outputId": "ec6631e5-a109-434d-e080-56ceffa71472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores = model.evaluate(val_generator)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\") \n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 3s 53ms/step\n",
            "Test Accuracy: 72.9166567325592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeuxyPp41Zhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E852QJRZ1bul",
        "colab_type": "code",
        "outputId": "f2c93571-36f1-4a3e-d2eb-59bc858a6fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}