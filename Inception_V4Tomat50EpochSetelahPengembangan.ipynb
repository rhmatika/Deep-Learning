{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception-V4Tomat50EpochAfterPengembangan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ-hTIsZckpr",
        "colab_type": "code",
        "outputId": "b0eaf608-fa93-4826-f390-dc1606db86f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import warnings\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D,Convolution2D,AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from keras import initializers\n",
        "from keras import backend as K\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0RvIiGXc7Oy",
        "colab_type": "code",
        "outputId": "d3d8bda7-76cf-4610-ed2a-42ec49d94134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdkTmIhddMEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_root = '/content/drive/My Drive/Dataset tomat/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCYu_eJsdQ0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, tuple((224,224)))   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfOPc7EEdmjD",
        "colab_type": "code",
        "outputId": "b2184112-453d-4fa8-c2e1-1011feacc633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".jpeg\") == True or image_directory.endswith(\".png\") == True or image_directory.endswith(\".JPG\") == True :\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Tomato___Bacterial_spot ...\n",
            "[INFO] Processing Tomato___Early_blight ...\n",
            "[INFO] Processing Tomato___Leaf_Mold ...\n",
            "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Processing Tomato___Late_blight ...\n",
            "[INFO] Image loading completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxx5sjiCnlLb",
        "colab_type": "code",
        "outputId": "c155984f-5126-4224-9aa4-638ade096dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_size = len(image_list)\n",
        "image_size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff4zeHlCnoD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYqvbym2nqZC",
        "colab_type": "code",
        "outputId": "a6208ee3-057d-4bda-96e5-424313e56915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
            " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
            " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dt3Q_y7nt2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abL0TFLTnvxl",
        "colab_type": "code",
        "outputId": "bfc8b5ad-37ad-4cb4-f98b-cbd90406c76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list,image_labels, test_size=0.2 , random_state =42) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la6OBsqYLnVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccbab7a3-cdbb-4179-89a7-60fc55d1cc3f"
      },
      "source": [
        "'''\n",
        "Copyright 2017 TensorFlow Authors and Kent Sommer\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "   http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "#########################################################################################\n",
        "# Implements the Inception Network v4 (http://arxiv.org/pdf/1602.07261v1.pdf) in Keras. #\n",
        "#########################################################################################\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x = np.divide(x, 255.0)\n",
        "    x = np.subtract(x, 0.5)\n",
        "    x = np.multiply(x, 2.0)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
        "              padding='same', strides=(1, 1), use_bias=False):\n",
        "    \"\"\"\n",
        "    Utility function to apply conv + BN. \n",
        "    (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
        "    \"\"\"\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "    x = Convolution2D(nb_filter, (num_row, num_col),\n",
        "                      strides=strides,\n",
        "                      padding=padding,\n",
        "                      use_bias=use_bias,\n",
        "                      kernel_regularizer=regularizers.l2(0.00004),\n",
        "                      kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_inception_a(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_reduction_a(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_inception_b(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
        "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_reduction_b(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def block_inception_c(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
        "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
        "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
        "\n",
        "\n",
        "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
        "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
        "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
        "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
        "    return x\n",
        "\n",
        "\n",
        "def inception_v4_base(input):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = -1\n",
        "\n",
        "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
        "\n",
        "    #Stem Block\n",
        "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
        "    net = conv2d_bn(net, 64, 3, 3)\n",
        "\n",
        "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
        "\n",
        "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
        "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "\n",
        "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
        "\n",
        "    # 35 x 35 x 384\n",
        "    # 4 x Inception-A blocks\n",
        "    for idx in range(4):\n",
        "    \tnet = block_inception_a(net)\n",
        "\n",
        "    # 35 x 35 x 384\n",
        "    # Reduction-A block\n",
        "    net = block_reduction_a(net)\n",
        "\n",
        "    # 17 x 17 x 1024\n",
        "    # 7 x Inception-B blocks\n",
        "    for idx in range(7):\n",
        "    \tnet = block_inception_b(net)\n",
        "\n",
        "    # 17 x 17 x 1024\n",
        "    # Reduction-B block\n",
        "    net = block_reduction_b(net)\n",
        "\n",
        "    # 8 x 8 x 1536\n",
        "    # 3 x Inception-C blocks\n",
        "    for idx in range(3):\n",
        "    \tnet = block_inception_c(net)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
        "    '''\n",
        "    Creates the inception v4 network\n",
        "\n",
        "    Args:\n",
        "    \tnum_classes: number of classes\n",
        "    \tdropout_keep_prob: float, the fraction to keep before final layer.\n",
        "    \n",
        "    Returns: \n",
        "    \tlogits: the logits outputs of the model.\n",
        "    '''\n",
        "\n",
        "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        inputs = Input((3, 224, 224))\n",
        "    else:\n",
        "        inputs = Input((224, 224, 3))\n",
        "\n",
        "    # Make inception base\n",
        "    x = inception_v4_base(inputs)\n",
        "\n",
        "\n",
        "    # Final pooling and prediction\n",
        "    if include_top:\n",
        "      \n",
        "        # Final pooling and prediction\n",
        "        # 1 x 1 x 1536\n",
        "        x = AveragePooling2D((8,8), padding='valid')(x)\n",
        "        x = Dropout(dropout_keep_prob)(x)\n",
        "        x = Flatten()(x)\n",
        "        # 1536\n",
        "        x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, x, name='inception_v4')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'imagenet':\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            if K.backend() == 'tensorflow':\n",
        "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "        if include_top:\n",
        "            weights_path = get_file(\n",
        "                'inception-v4_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='9fe79d77f793fe874470d84ca6ba4a3b')\n",
        "        else:\n",
        "            weights_path = get_file(\n",
        "                'inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                md5_hash='9296b46b5971573064d12e4669110969')\n",
        "        model.load_weights(weights_path, by_name=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model(num_classes=1001, dropout_prob=0.2, weights=None, include_top=False):\n",
        "    return inception_v4(num_classes, dropout_prob, weights, include_top)\n",
        "# ----------------------------------------------------------\n",
        "incept_model = create_model(num_classes=1001, dropout_prob=0.2, weights=None, include_top=False)\n",
        "incept_model.load_weights('/content/drive/My Drive/input/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for l in incept_model.layers: \n",
        "    if l is not None: l.trainable = True \n",
        "        \n",
        "x = incept_model.output\n",
        "x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "x = BatchNormalization()(x)\n",
        "#x = Dense(1024, activation='relu')(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=incept_model.input, outputs=predictions)        \n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 96)   55296       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 96)   288         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 96)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 54, 54, 160)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 54, 54, 64)   10240       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 54, 54, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 54, 54, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 54, 54, 64)   28672       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 54, 54, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 54, 54, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 54, 54, 64)   10240       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 54, 54, 64)   28672       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 54, 54, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 54, 54, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 54, 54, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 54, 54, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 52, 52, 96)   55296       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 52, 52, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 52, 52, 96)   288         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 52, 52, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 52, 52, 96)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 52, 52, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 52, 52, 192)  0           activation_6[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 192)  331776      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 192)  576         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 192)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 25, 25, 384)  0           activation_11[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 384)  0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 96)   55296       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 96)   288         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 96)   288         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 96)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 96)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 25, 25, 384)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 384)  0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 96)   55296       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 96)   288         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 96)   288         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 96)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 96)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 25, 25, 384)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 64)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 64)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 25, 25, 96)   55296       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 25, 25, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 25, 25, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 384)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 25, 25, 96)   82944       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 96)   288         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 25, 25, 96)   288         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 25, 25, 96)   288         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 96)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 25, 25, 96)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 25, 25, 96)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 25, 25, 384)  0           activation_26[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 25, 25, 64)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 25, 25, 64)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 25, 25, 64)   24576       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 25, 25, 96)   55296       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 25, 25, 64)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 25, 25, 96)   288         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 25, 25, 64)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 25, 25, 96)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 25, 25, 384)  0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 25, 25, 96)   36864       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 25, 25, 96)   55296       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 25, 25, 96)   82944       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 25, 25, 96)   36864       average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 25, 25, 96)   288         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 25, 25, 96)   288         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 25, 25, 96)   288         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 25, 25, 96)   288         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 25, 25, 96)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 25, 25, 96)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 25, 25, 96)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 25, 25, 96)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 25, 25, 384)  0           activation_33[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 25, 25, 192)  73728       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 25, 25, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 25, 25, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 25, 25, 224)  387072      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 25, 25, 224)  672         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 25, 25, 224)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 384)  1327104     concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 256)  516096      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 384)  1152        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 256)  768         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 384)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 256)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 384)  0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 12, 12, 1024) 0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  258048      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 224)  301056      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 192)  576         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 224)  672         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 192)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 224)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 224)  301056      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 224)  351232      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 224)  672         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 224)  672         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 224)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 224)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 1024) 0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 256)  401408      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 256)  401408      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 384)  1152        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 256)  768         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 256)  768         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 128)  384         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 384)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 256)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 256)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 128)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 12, 12, 1024) 0           activation_44[0][0]              \n",
            "                                                                 activation_47[0][0]              \n",
            "                                                                 activation_52[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  258048      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 224)  301056      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 192)  576         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 224)  672         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 192)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 224)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 224)  301056      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 224)  351232      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 224)  672         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 224)  672         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 224)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 224)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 1024) 0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 256)  401408      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 256)  401408      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 384)  1152        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 256)  768         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 256)  768         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 128)  384         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 384)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 256)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 256)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 128)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 12, 12, 1024) 0           activation_54[0][0]              \n",
            "                                                                 activation_57[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 224)  301056      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 224)  672         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 224)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 224)  301056      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 224)  351232      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 224)  672         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 224)  672         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 224)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 224)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 1024) 0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 256)  401408      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 256)  401408      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 384)  1152        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 256)  768         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 256)  768         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 128)  384         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 384)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 256)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 256)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 128)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 12, 12, 1024) 0           activation_64[0][0]              \n",
            "                                                                 activation_67[0][0]              \n",
            "                                                                 activation_72[0][0]              \n",
            "                                                                 activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 12, 12, 192)  576         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 12, 12, 192)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 12, 12, 192)  258048      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 12, 12, 192)  576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 12, 12, 192)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 12, 12, 224)  301056      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 12, 12, 224)  672         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 12, 12, 224)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 12, 12, 224)  301056      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 12, 12, 224)  351232      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 12, 12, 224)  672         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 12, 12, 224)  672         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 12, 12, 224)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 12, 12, 224)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 12, 12, 1024) 0           concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 12, 12, 256)  401408      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 12, 12, 256)  401408      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 384)  1152        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 12, 12, 256)  768         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 12, 12, 256)  768         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 12, 12, 128)  384         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 384)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 12, 12, 256)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 12, 12, 256)  0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 12, 12, 128)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 12, 12, 1024) 0           activation_74[0][0]              \n",
            "                                                                 activation_77[0][0]              \n",
            "                                                                 activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 12, 12, 192)  576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 12, 12, 192)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 12, 12, 192)  258048      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 12, 12, 192)  576         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 12, 12, 192)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 12, 12, 224)  301056      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 12, 12, 192)  576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 12, 12, 224)  672         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 12, 12, 192)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 12, 12, 224)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 12, 12, 224)  301056      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 12, 12, 224)  351232      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 12, 12, 224)  672         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 12, 12, 224)  672         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 12, 12, 224)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 12, 12, 224)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 12, 12, 1024) 0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 12, 12, 256)  401408      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 12, 12, 256)  401408      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 12, 12, 128)  131072      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 12, 12, 384)  1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 12, 12, 256)  768         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 12, 12, 256)  768         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 12, 12, 128)  384         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 12, 12, 384)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 12, 12, 256)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 12, 12, 256)  0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 12, 12, 128)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 12, 12, 1024) 0           activation_84[0][0]              \n",
            "                                                                 activation_87[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 12, 12, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 12, 12, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 12, 12, 192)  258048      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 12, 12, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 12, 12, 192)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 12, 12, 192)  196608      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 12, 12, 224)  301056      activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 12, 12, 192)  576         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 12, 12, 224)  672         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 12, 12, 192)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 12, 12, 224)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 12, 12, 224)  301056      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 12, 12, 224)  351232      activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 12, 12, 224)  672         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 12, 12, 224)  672         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 12, 12, 224)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 12, 12, 224)  0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 12, 12, 1024) 0           concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 12, 12, 384)  393216      concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 12, 12, 256)  401408      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 12, 12, 256)  401408      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 12, 12, 384)  1152        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 12, 12, 256)  768         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 12, 12, 256)  768         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 12, 12, 128)  384         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 12, 12, 384)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 12, 12, 256)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 12, 12, 256)  0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 12, 12, 128)  0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 12, 12, 1024) 0           activation_94[0][0]              \n",
            "                                                                 activation_97[0][0]              \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 12, 12, 192)  576         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 12, 12, 192)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 12, 12, 192)  258048      activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 12, 12, 192)  576         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 12, 12, 192)  0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 12, 12, 224)  301056      activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 12, 12, 192)  576         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 12, 12, 224)  672         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 12, 12, 192)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 12, 12, 224)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 12, 12, 224)  301056      activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 12, 12, 224)  351232      activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 12, 12, 224)  672         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 12, 12, 224)  672         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 12, 12, 224)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 12, 12, 224)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 12, 12, 1024) 0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 12, 12, 256)  401408      activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 12, 12, 256)  401408      activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 12, 12, 384)  1152        conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 12, 12, 256)  768         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 12, 12, 256)  768         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 12, 12, 128)  384         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 12, 12, 384)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 12, 12, 256)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 12, 12, 256)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 12, 12, 128)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 12, 12, 1024) 0           activation_104[0][0]             \n",
            "                                                                 activation_107[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 12, 12, 256)  262144      concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 12, 12, 256)  768         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 12, 12, 256)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 12, 12, 256)  458752      activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 12, 12, 256)  768         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 12, 12, 256)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 12, 12, 320)  573440      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 12, 12, 192)  576         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 12, 12, 320)  960         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 12, 12, 192)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 12, 12, 320)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 5, 5, 192)    331776      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 5, 5, 320)    921600      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 5, 5, 192)    576         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 5, 5, 320)    960         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 5, 5, 192)    0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 5, 5, 320)    0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 1024)   0           concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 5, 5, 1536)   0           activation_115[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 5, 5, 384)    1152        conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 5, 5, 384)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 5, 5, 448)    516096      activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 5, 5, 448)    1344        conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 5, 5, 448)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 5, 5, 512)    688128      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 5, 5, 384)    1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 5, 5, 512)    1536        conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 5, 5, 384)    0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 5, 5, 512)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 5, 5, 256)    294912      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 5, 5, 256)    294912      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 5, 5, 256)    393216      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 5, 5, 256)    393216      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 5, 5, 1536)   0           concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 5, 5, 256)    768         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 5, 5, 256)    768         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 5, 5, 256)    768         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 5, 5, 256)    768         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 5, 5, 256)    768         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 5, 5, 256)    0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 5, 5, 256)    0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 5, 5, 256)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 5, 5, 256)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 5, 5, 256)    768         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 5, 5, 256)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 5, 5, 512)    0           activation_122[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 5, 5, 512)    0           activation_127[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 5, 5, 256)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 5, 5, 1536)   0           activation_120[0][0]             \n",
            "                                                                 concatenate_17[0][0]             \n",
            "                                                                 concatenate_18[0][0]             \n",
            "                                                                 activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 5, 5, 384)    1152        conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 5, 5, 384)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 5, 5, 448)    516096      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 5, 5, 448)    1344        conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 5, 5, 448)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 5, 5, 512)    688128      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 5, 5, 384)    1152        conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 5, 5, 512)    1536        conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 5, 5, 384)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 5, 5, 512)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 5, 5, 256)    294912      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 5, 5, 256)    294912      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 5, 5, 256)    393216      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 5, 5, 256)    393216      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 5, 5, 1536)   0           concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 5, 5, 256)    768         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 5, 5, 256)    768         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 5, 5, 256)    768         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 5, 5, 256)    768         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 5, 5, 256)    768         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 5, 5, 256)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 5, 5, 256)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 5, 5, 256)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 5, 5, 256)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 5, 5, 256)    768         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 5, 5, 256)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 5, 5, 512)    0           activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 5, 5, 512)    0           activation_137[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 5, 5, 256)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 5, 5, 1536)   0           activation_130[0][0]             \n",
            "                                                                 concatenate_20[0][0]             \n",
            "                                                                 concatenate_21[0][0]             \n",
            "                                                                 activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 5, 5, 384)    1152        conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 5, 5, 384)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 5, 5, 448)    516096      activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 5, 5, 448)    1344        conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 5, 5, 448)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 5, 5, 512)    688128      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 5, 5, 384)    1152        conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 5, 5, 512)    1536        conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 5, 5, 384)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 5, 5, 512)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 5, 5, 256)    294912      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 5, 5, 256)    294912      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 5, 5, 256)    393216      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 5, 5, 256)    393216      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 5, 5, 1536)   0           concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 5, 5, 256)    768         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 5, 5, 256)    768         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 5, 5, 256)    768         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 5, 5, 256)    768         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 5, 5, 256)    768         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 5, 5, 256)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 5, 5, 256)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 5, 5, 256)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 5, 5, 256)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 5, 5, 256)    768         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 5, 5, 256)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 5, 5, 512)    0           activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 5, 5, 512)    0           activation_147[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 5, 5, 256)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 5, 5, 1536)   0           activation_140[0][0]             \n",
            "                                                                 concatenate_23[0][0]             \n",
            "                                                                 concatenate_24[0][0]             \n",
            "                                                                 activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 1536)         0           concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 1536)         6144        global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          786944      batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            3078        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 41,970,566\n",
            "Trainable params: 41,904,326\n",
            "Non-trainable params: 66,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkan5Ntpnx_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Define a function for a convolutional layer with batch normalization\n",
        "# #The commands in this function will be used very much, so it's simpler to define this function once. \n",
        "# def conv(input_, filters_, kernel_, strides_, bias_, padding_):\n",
        "#     conv_ = Conv2D(filters=filters_, kernel_size=kernel_, strides=strides_, use_bias=bias_, padding=padding_)(input_)\n",
        "#     #The batch normalization helps to prevent overfitting and better learning results by removing the covariance shift.\n",
        "#     conv_ = BatchNormalization(axis = -1, momentum = 0.9997, scale = False)(conv_)\n",
        "#     conv_ = Activation(\"relu\")(conv_)\n",
        "#     return conv_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cARQPIxrn1a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #All kinds of inception networks starting with a stem. The stem preprocesses \n",
        "# #the input.\n",
        "# def stem(input_):\n",
        "#     #First convolutional block\n",
        "#     stem_ = conv(input_, 32, (3,3), (2,2), False, \"valid\")\n",
        "#     stem_ = conv(stem_, 32, (1,3), (1,1), False, \"same\")\n",
        "#     stem_ = conv(stem_, 32, (3,1), (1,1), False, \"same\")\n",
        "#     stem_ = conv(stem_, 64, (1,3), (1,1), False, \"same\")\n",
        "#     stem_ = conv(stem_, 64, (3,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Instead of going deeper the network will becoming wider!\n",
        "#     stem_1 = conv(stem_, 96, (3,3), (2,2), False, \"valid\")\n",
        "#     stem_2 = MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"valid\")(stem_)\n",
        "#     #Concatenate stem_1 and stem_2\n",
        "#     stem_ = concatenate([stem_1, stem_2], axis = -1)\n",
        "    \n",
        "#     #In the next block we will also parallize two convolutional blocks\n",
        "#     #Here I reuse the two variable names from above\n",
        "#     stem_1 = conv(stem_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     stem_1 = conv(stem_1, 64, (7,1), (1,1), False, \"same\")\n",
        "#     stem_1 = conv(stem_1, 64, (1,7), (1,1), False, \"same\")\n",
        "#     stem_1 = conv(stem_1, 96, (1,3), (1,1), False, \"valid\")\n",
        "#     stem_1 = conv(stem_1, 96, (3,1), (1,1), False, \"valid\")\n",
        "#     stem_2 = conv(stem_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     stem_2 = conv(stem_2, 96, (3,3), (1,1), False, \"valid\")\n",
        "#     #Concatenate stem_1 and stem_2\n",
        "#     stem_ = concatenate([stem_1, stem_2], axis = -1)\n",
        "    \n",
        "#     #Third concatenation block\n",
        "#     #Reuse stem_1 and stem_2\n",
        "#     stem_1 = MaxPool2D(pool_size=(1,1), strides=(2,2), padding=\"valid\")(stem_)\n",
        "#     stem_2 = stem_1 = conv(stem_, 192, (3,3), (1,1), False, \"valid\")\n",
        "#     #Concatenate stem_1 and stem_2\n",
        "#     stem_ = concatenate([stem_1, stem_2], axis = -1)\n",
        "    \n",
        "#     return stem_  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO46g9_Pn4Dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def inception_A(input_):\n",
        "#     #In this block we parallize four convolutional blocks\n",
        "#     #First\n",
        "#     A_1 = conv(input_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     A_1 = conv(A_1, 96, (1,3), (1,1), False, \"same\")\n",
        "#     A_1 = conv(A_1, 96, (3,1), (1,1), False, \"same\")\n",
        "#     A_1 = conv(A_1, 96, (1,3), (1,1), False, \"same\")\n",
        "    \n",
        "    \n",
        "#     #Second\n",
        "#     A_2 = conv(input_, 64, (1,1), (1,1), False, \"same\")\n",
        "#     A_2 = conv(A_2, 96, (1,3), (1,1), False, \"same\")\n",
        "#     A_2 = conv(A_2, 96, (3,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     A_3 = conv(input_, 96, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Fourth\n",
        "#     A_4 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input_)\n",
        "#     A_4 = conv(A_4, 96, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     A = concatenate([A_1, A_2, A_3, A_4], axis=-1)\n",
        "    \n",
        "#     return A    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U79A8hMHn6Ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def inception_B(input_):\n",
        "#     #Similiar to A\n",
        "#     #In this block we also parallize four convolutional blocks\n",
        "    \n",
        "#     #First\n",
        "#     B_1 = conv(input_, 192, (1,1), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 192, (1,7), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 224, (7,1), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 224, (1,7), (1,1), False, \"same\")\n",
        "#     B_1 = conv(B_1, 256, (7,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Second\n",
        "#     B_2 = conv(input_, 192, (1,1), (1,1), False, \"same\")\n",
        "#     B_2 = conv(B_2, 224, (7,1), (1,1), False, \"same\")\n",
        "#     B_2 = conv(B_2, 256, (1,7), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     B_3 = conv(input_, 384, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Fourth\n",
        "#     B_4 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input_)\n",
        "#     B_4 = conv(B_4, 128, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     B = concatenate([B_1, B_2, B_3, B_4], axis=-1)\n",
        "    \n",
        "#     return B    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qReZNAwn8kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def inception_C(input_):\n",
        "#     #This block is different to the structures of the other two blocks\n",
        "    \n",
        "#     #First\n",
        "#     C_1 = conv(input_, 384, (1,1), (1,1), False, \"same\")\n",
        "#     C_1 = conv(C_1, 448, (1,3), (1,1), False, \"same\")\n",
        "#     C_1 = conv(C_1, 512, (3,1), (1,1), False, \"same\")\n",
        "#     #Split it up again\n",
        "#     C_11 = conv(C_1, 256, (1,3), (1,1), False, \"same\")\n",
        "#     C_12 = conv(C_1, 256, (3,1), (1,1), False, \"same\")\n",
        "#     #Concatenate it again\n",
        "#     C_1 = concatenate([C_11, C_12], axis=-1)\n",
        "    \n",
        "#     #Second\n",
        "#     C_2 = conv(input_, 384, (1,1), (1,1), False, \"same\")\n",
        "#     #Split it up again\n",
        "#     C_21 = conv(C_2, 256, (1,3), (1,1), False, \"same\")\n",
        "#     C_22 = conv(C_2, 256, (3,1), (1,1), False, \"same\")\n",
        "#     #Concatenate it again\n",
        "#     C_2 = concatenate([C_21, C_22], axis=-1)\n",
        "    \n",
        "#     #Third\n",
        "#     C_3 = conv(input_, 256, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     #Fourth\n",
        "#     C_4 = AveragePooling2D((3, 3), strides = (1, 1), padding = \"same\")(input_)\n",
        "#     C_4 = conv(C_4, 128, (1,1), (1,1), False, \"same\")\n",
        "    \n",
        "#     C = concatenate([C_1, C_2, C_3, C_4], axis=-1)\n",
        "    \n",
        "#     return C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzfUiKzmn--p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def reduction_1(input_):\n",
        "#     #Three parallized branches\n",
        "#     #We must choose four parameters (k,l,m,n) depending on the used network\n",
        "#     #The parameters are listed in a look up table in Paper 2\n",
        "#     k = 192\n",
        "#     l = 224\n",
        "#     m = 256\n",
        "#     n = 384\n",
        "    \n",
        "#     #First\n",
        "#     R_1 = conv(input_, k, (1,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, l, (1,3), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, l, (3,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, m, (3,3), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Second\n",
        "#     R_2 = conv(input_, n, (1,3), (2,2), False, \"same\")\n",
        "#     R_2 = conv(input_, n, (3,1), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     R_3 = MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"same\")(input_)\n",
        "    \n",
        "#     R = concatenate([R_1, R_2, R_3], axis=-1)\n",
        "    \n",
        "#     return R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoPfZkYloBam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def reduction_2(input_):\n",
        "#     #Second reduction module\n",
        "    \n",
        "#     #First\n",
        "#     R_1 = conv(input_, 256, (1,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, 256, (1,7), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, 320, (7,1), (1,1), False, \"same\")\n",
        "#     R_1 = conv(R_1, 320, (3,3), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Second\n",
        "#     R_2 = conv(input_, 192, (1,1), (1,1), False, \"same\")\n",
        "#     R_2 = conv(R_2, 192, (1,1), (2,2), False, \"same\")\n",
        "    \n",
        "#     #Third\n",
        "#     R_3 = MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"same\")(input_)\n",
        "    \n",
        "#     R = concatenate([R_1, R_2, R_3], axis=-1)\n",
        "    \n",
        "#     return R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpWL9L9uoDl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def pure_inception_v4(load_weights=True):\n",
        "    \n",
        "#     starter = Input((224, 224, 3))\n",
        "    \n",
        "#     #Start with the stem\n",
        "#     inc = stem(starter)\n",
        "    \n",
        "#     #inception block A\n",
        "#     inc = inception_A(inc)\n",
        "#     inc = Dropout(0.2)(inc)\n",
        "    \n",
        "#     #First Reduction\n",
        "#     inc = reduction_1(inc)\n",
        "    \n",
        "#     #innception block B\n",
        "#     inc = inception_B(inc)    \n",
        "#     inc = Dropout(0.2)(inc)\n",
        "    \n",
        "#     #Second Reduction\n",
        "#     inc = reduction_2(inc)\n",
        "    \n",
        "#     #inception block C\n",
        "#     inc = inception_C(inc)\n",
        "    \n",
        "#     #Average pooling\n",
        "#     inc = AveragePooling2D((3, 3))(inc)\n",
        "\n",
        "#     # Dropout\n",
        "#     inc = Dropout(0.2)(inc) # Keep dropout 0.2 as mentioned in the paper\n",
        "#     inc = Flatten()(inc)\n",
        "\n",
        "#     # Output layer\n",
        "#     output = Dense(units = 6 , activation = \"softmax\")(inc)\n",
        "    \n",
        "#     model = Model(starter, output, name = \"Inception-v4\")   \n",
        "        \n",
        "#     return model    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0moYIQTdoGZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model = pure_inception_v4()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtW0Qiy7oMoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(Model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSTZHNolvfIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:40]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[40:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQiovlHrvirP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We'll use the RMSprop optimizer with a learning rate of 0.0001\n",
        "#We'll use binary_crossentropy loss because its a binary classification\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=0.0001), metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS7yX9C_vkf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets create the augmentation configuration\n",
        "#This helps prevent overfitting, since we are using a small dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,   #Scale the image between 0 and 1\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UZ6Xy3-vpWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the image generators\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
        "val_generator = val_datagen.flow(x_test, y_test,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6GXPXGSULBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HsVJ0x3vsji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e021aa5-a0ab-4ff0-a012-a0c841666ab0"
      },
      "source": [
        "%%time\n",
        "#The training part\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=len(x_train) // 32,\n",
        "                              epochs=100,\n",
        "                              validation_data=val_generator)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 17s 553ms/step - loss: 0.8705 - acc: 0.9538 - val_loss: 1.2969 - val_acc: 0.8306\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.8215 - acc: 0.9776 - val_loss: 1.7976 - val_acc: 0.7208\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 15s 513ms/step - loss: 0.8052 - acc: 0.9819 - val_loss: 2.4171 - val_acc: 0.7208\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 15s 510ms/step - loss: 0.7941 - acc: 0.9825 - val_loss: 1.2160 - val_acc: 0.8333\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 0.7918 - acc: 0.9847 - val_loss: 1.4205 - val_acc: 0.8333\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 0.7804 - acc: 0.9885 - val_loss: 1.5349 - val_acc: 0.8257\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 0.7836 - acc: 0.9892 - val_loss: 2.4361 - val_acc: 0.7292\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 0.7809 - acc: 0.9873 - val_loss: 3.4487 - val_acc: 0.7208\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 0.7753 - acc: 0.9903 - val_loss: 3.4908 - val_acc: 0.7333\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 0.7666 - acc: 0.9905 - val_loss: 2.8817 - val_acc: 0.7333\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.7634 - acc: 0.9922 - val_loss: 1.3122 - val_acc: 0.8333\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 15s 495ms/step - loss: 0.7673 - acc: 0.9936 - val_loss: 1.5688 - val_acc: 0.8035\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 15s 495ms/step - loss: 0.7713 - acc: 0.9898 - val_loss: 3.6056 - val_acc: 0.7333\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 15s 494ms/step - loss: 0.7571 - acc: 0.9944 - val_loss: 1.6252 - val_acc: 0.7153\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 0.7540 - acc: 0.9937 - val_loss: 2.7070 - val_acc: 0.7153\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.7442 - acc: 0.9967 - val_loss: 2.1549 - val_acc: 0.7292\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.7490 - acc: 0.9943 - val_loss: 4.6611 - val_acc: 0.7208\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 0.7481 - acc: 0.9934 - val_loss: 1.4455 - val_acc: 0.7153\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 0.7425 - acc: 0.9943 - val_loss: 2.1646 - val_acc: 0.7153\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 15s 508ms/step - loss: 0.7380 - acc: 0.9955 - val_loss: 2.0406 - val_acc: 0.7208\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 0.7435 - acc: 0.9934 - val_loss: 3.8645 - val_acc: 0.7208\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 0.7320 - acc: 0.9948 - val_loss: 4.5493 - val_acc: 0.7208\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 0.7262 - acc: 0.9958 - val_loss: 1.6021 - val_acc: 0.7194\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.7218 - acc: 0.9953 - val_loss: 2.5578 - val_acc: 0.7292\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 0.7236 - acc: 0.9964 - val_loss: 2.5394 - val_acc: 0.7194\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.7125 - acc: 0.9967 - val_loss: 3.3260 - val_acc: 0.7194\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.7137 - acc: 0.9946 - val_loss: 1.3523 - val_acc: 0.8090\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 15s 508ms/step - loss: 0.7094 - acc: 0.9974 - val_loss: 1.5787 - val_acc: 0.7708\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.6998 - acc: 0.9969 - val_loss: 1.7867 - val_acc: 0.7215\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 15s 512ms/step - loss: 0.7003 - acc: 0.9944 - val_loss: 3.2916 - val_acc: 0.7208\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 15s 511ms/step - loss: 0.6958 - acc: 0.9951 - val_loss: 3.2535 - val_acc: 0.7153\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 0.6853 - acc: 0.9981 - val_loss: 2.3097 - val_acc: 0.7153\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 0.6901 - acc: 0.9955 - val_loss: 3.2468 - val_acc: 0.7153\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 15s 507ms/step - loss: 0.6797 - acc: 0.9976 - val_loss: 4.0746 - val_acc: 0.7333\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 0.6838 - acc: 0.9972 - val_loss: 4.0509 - val_acc: 0.7333\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.6723 - acc: 0.9972 - val_loss: 3.5910 - val_acc: 0.7194\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 0.6725 - acc: 0.9969 - val_loss: 1.6112 - val_acc: 0.7333\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.6712 - acc: 0.9957 - val_loss: 2.5682 - val_acc: 0.7153\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.6612 - acc: 0.9979 - val_loss: 1.8413 - val_acc: 0.7153\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 0.6637 - acc: 0.9965 - val_loss: 1.8065 - val_acc: 0.7333\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 15s 498ms/step - loss: 0.6503 - acc: 0.9984 - val_loss: 2.1410 - val_acc: 0.7333\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.6500 - acc: 0.9965 - val_loss: 1.4455 - val_acc: 0.8333\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.6454 - acc: 0.9972 - val_loss: 2.5097 - val_acc: 0.7153\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 15s 509ms/step - loss: 0.6411 - acc: 0.9977 - val_loss: 1.2425 - val_acc: 0.7153\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 0.6444 - acc: 0.9955 - val_loss: 1.4076 - val_acc: 0.7625\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.6392 - acc: 0.9972 - val_loss: 2.3707 - val_acc: 0.7333\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.6394 - acc: 0.9965 - val_loss: 1.1290 - val_acc: 0.8292\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 15s 509ms/step - loss: 0.6276 - acc: 0.9972 - val_loss: 1.1428 - val_acc: 0.8333\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.6288 - acc: 0.9974 - val_loss: 1.1793 - val_acc: 0.8333\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 0.6163 - acc: 0.9997 - val_loss: 1.7813 - val_acc: 0.7208\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.6200 - acc: 0.9960 - val_loss: 2.2181 - val_acc: 0.7153\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.6136 - acc: 0.9979 - val_loss: 1.1192 - val_acc: 0.8333\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.6075 - acc: 0.9991 - val_loss: 3.2975 - val_acc: 0.7208\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 0.6058 - acc: 0.9983 - val_loss: 3.5868 - val_acc: 0.7208\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.6075 - acc: 0.9967 - val_loss: 1.4383 - val_acc: 0.7153\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 0.6009 - acc: 0.9970 - val_loss: 1.1226 - val_acc: 0.8333\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 0.6011 - acc: 0.9964 - val_loss: 1.3509 - val_acc: 0.7153\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.6062 - acc: 0.9969 - val_loss: 1.2885 - val_acc: 0.7208\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.5957 - acc: 0.9970 - val_loss: 1.5952 - val_acc: 0.7153\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.5935 - acc: 0.9972 - val_loss: 1.4772 - val_acc: 0.7208\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 0.5963 - acc: 0.9967 - val_loss: 3.7078 - val_acc: 0.7208\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 0.5967 - acc: 0.9953 - val_loss: 1.3875 - val_acc: 0.7208\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 0.5919 - acc: 0.9960 - val_loss: 1.4623 - val_acc: 0.7153\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.5847 - acc: 0.9974 - val_loss: 1.3126 - val_acc: 0.8333\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.5775 - acc: 0.9986 - val_loss: 1.3021 - val_acc: 0.7333\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 15s 498ms/step - loss: 0.5840 - acc: 0.9964 - val_loss: 1.7893 - val_acc: 0.8333\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.5713 - acc: 0.9984 - val_loss: 1.7011 - val_acc: 0.7236\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 0.5772 - acc: 0.9958 - val_loss: 2.8964 - val_acc: 0.7333\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.5685 - acc: 0.9983 - val_loss: 2.8235 - val_acc: 0.7194\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.5680 - acc: 0.9972 - val_loss: 3.3855 - val_acc: 0.7208\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 15s 501ms/step - loss: 0.5616 - acc: 0.9979 - val_loss: 1.7951 - val_acc: 0.7208\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.5573 - acc: 0.9986 - val_loss: 1.7848 - val_acc: 0.7194\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.5559 - acc: 0.9981 - val_loss: 4.9423 - val_acc: 0.7208\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 15s 497ms/step - loss: 0.5533 - acc: 0.9983 - val_loss: 1.4602 - val_acc: 0.7208\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.5495 - acc: 0.9990 - val_loss: 4.3769 - val_acc: 0.7208\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.5457 - acc: 0.9976 - val_loss: 1.2223 - val_acc: 0.7306\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.5413 - acc: 0.9990 - val_loss: 1.2235 - val_acc: 0.8333\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 15s 502ms/step - loss: 0.5454 - acc: 0.9972 - val_loss: 3.1846 - val_acc: 0.7208\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 15s 497ms/step - loss: 0.5388 - acc: 0.9983 - val_loss: 2.4007 - val_acc: 0.7208\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 15s 504ms/step - loss: 0.5399 - acc: 0.9972 - val_loss: 3.8482 - val_acc: 0.7153\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.5320 - acc: 0.9993 - val_loss: 1.5888 - val_acc: 0.7153\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.5280 - acc: 0.9986 - val_loss: 2.0244 - val_acc: 0.7153\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 15s 505ms/step - loss: 0.5288 - acc: 0.9965 - val_loss: 1.8977 - val_acc: 0.7292\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.5310 - acc: 0.9965 - val_loss: 2.0170 - val_acc: 0.7292\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 15s 506ms/step - loss: 0.5247 - acc: 0.9976 - val_loss: 1.7503 - val_acc: 0.7292\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.5329 - acc: 0.9965 - val_loss: 1.9622 - val_acc: 0.7125\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.5173 - acc: 0.9997 - val_loss: 1.8004 - val_acc: 0.7167\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.5291 - acc: 0.9964 - val_loss: 1.4304 - val_acc: 0.7153\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.5119 - acc: 0.9993 - val_loss: 2.6583 - val_acc: 0.7292\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.5104 - acc: 0.9972 - val_loss: 4.0052 - val_acc: 0.7194\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 15s 497ms/step - loss: 0.5154 - acc: 0.9970 - val_loss: 1.6509 - val_acc: 0.7208\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.5081 - acc: 0.9979 - val_loss: 1.0897 - val_acc: 0.8083\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 15s 492ms/step - loss: 0.5057 - acc: 0.9976 - val_loss: 1.0643 - val_acc: 0.7160\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 15s 487ms/step - loss: 0.5072 - acc: 0.9976 - val_loss: 3.2673 - val_acc: 0.7153\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.4998 - acc: 0.9974 - val_loss: 2.3258 - val_acc: 0.7292\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 0.4934 - acc: 0.9990 - val_loss: 1.7204 - val_acc: 0.7292\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 15s 485ms/step - loss: 0.4944 - acc: 0.9986 - val_loss: 2.3325 - val_acc: 0.7292\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 15s 489ms/step - loss: 0.4958 - acc: 0.9976 - val_loss: 1.9619 - val_acc: 0.7292\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 15s 490ms/step - loss: 0.4909 - acc: 0.9976 - val_loss: 1.9671 - val_acc: 0.7292\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 15s 500ms/step - loss: 0.4848 - acc: 0.9988 - val_loss: 2.1491 - val_acc: 0.7292\n",
            "CPU times: user 38min 33s, sys: 2min 26s, total: 40min 59s\n",
            "Wall time: 25min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxBEkRkmoU4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aug = ImageDataGenerator(\n",
        "#     rotation_range=25, width_shift_range=0.1,\n",
        "#     height_shift_range=0.1, shear_range=0.2, \n",
        "#     zoom_range=0.2,horizontal_flip=True, \n",
        "#     fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JID7NdgoXY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model.compile(loss=\"binary_crossentropy\", optimizer='Adam',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8qWcqbSoZfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = Model.fit_generator(\n",
        "#     aug.flow(x_train, y_train, batch_size=4),\n",
        "#     steps_per_epoch=len(x_train)//4,\n",
        "#     epochs=50,\n",
        "#     validation_data=(x_test, y_test),\n",
        "#     max_queue_size=4*2,\n",
        "#     verbose=1\n",
        "#     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AxTr7tU1NfS",
        "colab_type": "code",
        "outputId": "d43ec9d5-fd59-498e-b2da-53603426e83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores = model.evaluate(val_generator)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\") \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 114ms/step\n",
            "Test Accuracy: 72.91666865348816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeuxyPp41Zhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E852QJRZ1bul",
        "colab_type": "code",
        "outputId": "1cfaf3ae-f1aa-4811-b49d-9b0169562b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}