{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TugasVGG16.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GDK5h38JD1q2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":83},"outputId":"8745bad2-e352-4dcd-d937-2fcf9404cda8","executionInfo":{"status":"ok","timestamp":1583324255406,"user_tz":-480,"elapsed":2574,"user":{"displayName":"nur afra reskianty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcGg03GK2WC8lnLJQMlDQ-04yDdEtW47AvL7noLA=s64","userId":"13233168393341877204"}}},"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import mnist\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation, Reshape\n","from keras.optimizers import RMSprop\n","from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n","from keras.utils import np_utils"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"leeDxeu3D1uj","colab_type":"code","outputId":"bffd9d24-2e77-4832-f8a0-ec1edcf29421","executionInfo":{"status":"ok","timestamp":1583324267073,"user_tz":-480,"elapsed":2841,"user":{"displayName":"nur afra reskianty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcGg03GK2WC8lnLJQMlDQ-04yDdEtW47AvL7noLA=s64","userId":"13233168393341877204"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n","X_train original shape (60000, 28, 28)\n","y_train original shape (60000,)\n","X_test original shape (10000, 28, 28)\n","y_test original shape (10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uMJCElH6D1wi","colab_type":"code","outputId":"fabd33c5-4a23-4ce3-970c-1c9d5561bc97","executionInfo":{"status":"ok","timestamp":1583324271803,"user_tz":-480,"elapsed":1402,"user":{"displayName":"nur afra reskianty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcGg03GK2WC8lnLJQMlDQ-04yDdEtW47AvL7noLA=s64","userId":"13233168393341877204"}},"colab":{"base_uri":"https://localhost:8080/","height":299}},"source":["plt.imshow(X_train[12], cmap='gray')\n","plt.title('Class '+ str(y_train[12]))"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Class 3')"]},"metadata":{"tags":[]},"execution_count":3},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"bDQEJ0qjD1z3","colab_type":"code","colab":{}},"source":["y_train_onehot = to_categorical(y_train, num_classes=None, dtype='float32')\n","EPOCHS = 50\n","BATCH_SIZE = 128"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZ_Q1WsuE6bh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":110},"outputId":"da515279-ec1d-4a7e-8fa3-d681bdc80a05","executionInfo":{"status":"ok","timestamp":1583324277831,"user_tz":-480,"elapsed":1154,"user":{"displayName":"nur afra reskianty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcGg03GK2WC8lnLJQMlDQ-04yDdEtW47AvL7noLA=s64","userId":"13233168393341877204"}}},"source":["optimizer = RMSprop(lr=1e-4)\n","objective = 'binary_crossentropy'\n","\n","def vgg16():\n","    model = Sequential()\n","    model.add(Reshape((28, 28, 1)))\n","    model.add(Conv2D(64, (3, 3), padding='same', input_shape=((28, 28, 1)), activation='relu'))\n","    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n","\n","    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n","    \n","    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n","    \n","    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n","\n","    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","    #model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n","\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.5))\n","    \n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","\n","    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","\n","model = vgg16()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EZHsQs3mE__X","colab_type":"code","colab":{}},"source":["class LossHistory(Callback):\n","    def on_train_begin(self, logs={}):\n","        self.losses = []\n","        self.val_losses = []\n","        self.acc = []\n","        self.val_acc = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","        self.val_losses.append(logs.get('val_loss'))\n","        self.acc.append(logs.get('acc'))\n","        self.val_acc.append(logs.get('val_acc'))\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')\n","\n","def run_vgg16():\n","    \n","    history = LossHistory()\n","    model.fit(X_train, y_train_onehot, batch_size=BATCH_SIZE , epochs=EPOCHS,\n","              validation_split=0.25, verbose=1, shuffle=True, callbacks=[history, early_stopping])\n","    \n","\n","    predictions = model.predict(X_test, verbose=0)\n","    return predictions, history\n","\n","def test_accuracy():\n","    err = []\n","    t = 0\n","    for i in range(predictions.shape[0]):\n","        if (np.argmax(predictions[i]) == y_test[i]):\n","            t = t+1\n","        else:\n","            err.append(i)\n","    return t, float(t)*100/predictions.shape[0], err"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YK9sQPakFSOL","colab_type":"code","outputId":"caffe9be-a515-484a-ebef-81f4dad3eb93","executionInfo":{"status":"ok","timestamp":1583324994912,"user_tz":-480,"elapsed":707304,"user":{"displayName":"nur afra reskianty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgcGg03GK2WC8lnLJQMlDQ-04yDdEtW47AvL7noLA=s64","userId":"13233168393341877204"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%time\n","predictions, history = run_vgg16()\n","p = test_accuracy()\n","print(\"Test accuracy: {} %\".format(p[1]))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 45000 samples, validate on 15000 samples\n","Epoch 1/50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","45000/45000 [==============================] - 29s 650us/step - loss: 0.1265 - acc: 0.9575 - val_loss: 0.0423 - val_acc: 0.9873\n","Epoch 2/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0231 - acc: 0.9939 - val_loss: 0.0169 - val_acc: 0.9955\n","Epoch 3/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.0320 - val_acc: 0.9906\n","Epoch 4/50\n","45000/45000 [==============================] - 14s 308us/step - loss: 0.0097 - acc: 0.9977 - val_loss: 0.0097 - val_acc: 0.9973\n","Epoch 5/50\n","45000/45000 [==============================] - 14s 309us/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0199 - val_acc: 0.9958\n","Epoch 6/50\n","45000/45000 [==============================] - 14s 301us/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0097 - val_acc: 0.9980\n","Epoch 7/50\n","45000/45000 [==============================] - 14s 300us/step - loss: 0.0049 - acc: 0.9989 - val_loss: 0.0113 - val_acc: 0.9977\n","Epoch 8/50\n","45000/45000 [==============================] - 13s 300us/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0111 - val_acc: 0.9973\n","Epoch 9/50\n","45000/45000 [==============================] - 14s 302us/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0140 - val_acc: 0.9975\n","Epoch 10/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0102 - val_acc: 0.9983\n","Epoch 11/50\n","45000/45000 [==============================] - 14s 304us/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0137 - val_acc: 0.9982\n","Epoch 12/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0080 - val_acc: 0.9984\n","Epoch 13/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.0154 - val_acc: 0.9980\n","Epoch 14/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0045 - acc: 0.9992 - val_loss: 0.0113 - val_acc: 0.9977\n","Epoch 15/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0039 - acc: 0.9993 - val_loss: 0.0132 - val_acc: 0.9982\n","Epoch 16/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0153 - val_acc: 0.9984\n","Epoch 17/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0235 - val_acc: 0.9927\n","Epoch 18/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0190 - val_acc: 0.9977\n","Epoch 19/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.0164 - val_acc: 0.9977\n","Epoch 20/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0158 - val_acc: 0.9978\n","Epoch 21/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.0095 - val_acc: 0.9979\n","Epoch 22/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0175 - val_acc: 0.9982\n","Epoch 23/50\n","45000/45000 [==============================] - 14s 304us/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0159 - val_acc: 0.9984\n","Epoch 24/50\n","45000/45000 [==============================] - 14s 309us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0469 - val_acc: 0.9966\n","Epoch 25/50\n","45000/45000 [==============================] - 14s 303us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0218 - val_acc: 0.9981\n","Epoch 26/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0247 - val_acc: 0.9974\n","Epoch 27/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0221 - val_acc: 0.9982\n","Epoch 28/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.0178 - val_acc: 0.9982\n","Epoch 29/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0078 - acc: 0.9992 - val_loss: 0.0284 - val_acc: 0.9980\n","Epoch 30/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0100 - acc: 0.9990 - val_loss: 0.0148 - val_acc: 0.9980\n","Epoch 31/50\n","45000/45000 [==============================] - 14s 308us/step - loss: 0.0058 - acc: 0.9993 - val_loss: 0.0243 - val_acc: 0.9975\n","Epoch 32/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0079 - acc: 0.9992 - val_loss: 0.0266 - val_acc: 0.9979\n","Epoch 33/50\n","45000/45000 [==============================] - 14s 304us/step - loss: 0.0094 - acc: 0.9991 - val_loss: 0.0204 - val_acc: 0.9981\n","Epoch 34/50\n","45000/45000 [==============================] - 13s 299us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0228 - val_acc: 0.9983\n","Epoch 35/50\n","45000/45000 [==============================] - 13s 298us/step - loss: 0.0041 - acc: 0.9994 - val_loss: 0.0236 - val_acc: 0.9981\n","Epoch 36/50\n","45000/45000 [==============================] - 14s 309us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0246 - val_acc: 0.9981\n","Epoch 37/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0117 - acc: 0.9991 - val_loss: 0.0183 - val_acc: 0.9982\n","Epoch 38/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0095 - acc: 0.9990 - val_loss: 0.0239 - val_acc: 0.9977\n","Epoch 39/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0083 - acc: 0.9993 - val_loss: 0.0360 - val_acc: 0.9976\n","Epoch 40/50\n","45000/45000 [==============================] - 14s 308us/step - loss: 0.0169 - acc: 0.9987 - val_loss: 0.0427 - val_acc: 0.9973\n","Epoch 41/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0062 - acc: 0.9993 - val_loss: 0.0262 - val_acc: 0.9976\n","Epoch 42/50\n","45000/45000 [==============================] - 14s 304us/step - loss: 0.0068 - acc: 0.9994 - val_loss: 0.0399 - val_acc: 0.9972\n","Epoch 43/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0097 - acc: 0.9991 - val_loss: 0.0210 - val_acc: 0.9982\n","Epoch 44/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0164 - acc: 0.9989 - val_loss: 0.0208 - val_acc: 0.9971\n","Epoch 45/50\n","45000/45000 [==============================] - 14s 306us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0141 - val_acc: 0.9981\n","Epoch 46/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0116 - acc: 0.9991 - val_loss: 0.0254 - val_acc: 0.9980\n","Epoch 47/50\n","45000/45000 [==============================] - 14s 305us/step - loss: 0.0087 - acc: 0.9993 - val_loss: 0.0203 - val_acc: 0.9981\n","Epoch 48/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0090 - acc: 0.9991 - val_loss: 0.0325 - val_acc: 0.9979\n","Epoch 49/50\n","45000/45000 [==============================] - 14s 308us/step - loss: 0.0106 - acc: 0.9989 - val_loss: 0.0257 - val_acc: 0.9974\n","Epoch 50/50\n","45000/45000 [==============================] - 14s 307us/step - loss: 0.0080 - acc: 0.9993 - val_loss: 0.0510 - val_acc: 0.9968\n","Test accuracy: 98.72 %\n","CPU times: user 7min 14s, sys: 2min 14s, total: 9min 28s\n","Wall time: 11min 45s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qTBHLoiLNZPg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}